{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6822f73-4213-491c-8d33-6e57c5dfbff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T11:29:15.496250Z",
     "iopub.status.busy": "2024-05-31T11:29:15.496168Z",
     "iopub.status.idle": "2024-05-31T11:29:19.603674Z",
     "shell.execute_reply": "2024-05-31T11:29:19.603357Z",
     "shell.execute_reply.started": "2024-05-31T11:29:15.496240Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/31 14:29:17 WARN Utils: Your hostname, Ugurs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.0.30 instead (on interface en0)\n",
      "24/05/31 14:29:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/31 14:29:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/31 14:29:19 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('pySparkSetup').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5067a057-b84b-4760-b5d1-a860df43222c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T11:29:19.604348Z",
     "iopub.status.busy": "2024-05-31T11:29:19.604213Z",
     "iopub.status.idle": "2024-05-31T11:29:25.710207Z",
     "shell.execute_reply": "2024-05-31T11:29:25.709944Z",
     "shell.execute_reply.started": "2024-05-31T11:29:19.604336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "weather = spark.read.parquet(\"/Users/ugurkalkavan/Downloads/m06sparkbasics/weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "297c39d1-3cdf-43fa-bff0-d9c1d5d5d3b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T11:29:25.710775Z",
     "iopub.status.busy": "2024-05-31T11:29:25.710653Z",
     "iopub.status.idle": "2024-05-31T11:29:25.717062Z",
     "shell.execute_reply": "2024-05-31T11:29:25.716839Z",
     "shell.execute_reply.started": "2024-05-31T11:29:25.710766Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'true'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.parquet.filterPushdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b29c73c0-da4e-4f11-940c-ca17d4f118b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T11:29:25.717531Z",
     "iopub.status.busy": "2024-05-31T11:29:25.717425Z",
     "iopub.status.idle": "2024-05-31T11:29:25.719910Z",
     "shell.execute_reply": "2024-05-31T11:29:25.719713Z",
     "shell.execute_reply.started": "2024-05-31T11:29:25.717524Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'false'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.parquet.aggregatePushdown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb884277-8edb-434c-b3ba-1ce9e3b8d6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T16:02:04.039099Z",
     "iopub.status.busy": "2024-05-30T16:02:04.038467Z",
     "iopub.status.idle": "2024-05-30T16:02:04.045290Z",
     "shell.execute_reply": "2024-05-30T16:02:04.044651Z",
     "shell.execute_reply.started": "2024-05-30T16:02:04.039067Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "def get_high_cardinality_columns_ratio(df, threshold_ratio):\n",
    "    \"\"\"DataFrame'deki her bir sütunun cardinality'sini hesaplar ve cardinality'si\n",
    "    belirli bir eşik değerinin üzerinde olan sütunları döndürür.\"\"\"\n",
    "    column_list = df.columns\n",
    "    high_cardinality_columns = []\n",
    "    total_count = df.count()\n",
    "\n",
    "    for column in column_list:\n",
    "        count = df.agg(approx_count_distinct(column)).collect()[0][0]\n",
    "        ratio = count / total_count\n",
    "        if ratio > threshold_ratio:\n",
    "            high_cardinality_columns.append((column, count, ratio))\n",
    "\n",
    "    return high_cardinality_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66167b3e-b7b8-4aa5-8a0c-6854f9a4037a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T16:01:13.399242Z",
     "iopub.status.busy": "2024-05-30T16:01:13.398829Z",
     "iopub.status.idle": "2024-05-30T16:01:33.125185Z",
     "shell.execute_reply": "2024-05-30T16:01:33.124666Z",
     "shell.execute_reply.started": "2024-05-30T16:01:13.399216Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Eşik değerini belirleyin. Bu, cardinality oranının ne kadar yüksek kabul edildiğini belirlemek için kullanılır.\n",
    "# Bu değer, veri kümenize, uygulamanıza ve performansınıza bağlı olarak ayarlanmalıdır.\n",
    "threshold_ratio = 0.75\n",
    "\n",
    "# DataFrame'deki her bir sütun için cardinality oranını hesapla ve yüksek cardinality'li sütunları bul\n",
    "high_cardinality_columns = get_high_cardinality_columns_ratio(weather, threshold_ratio)\n",
    "\n",
    "for column, count, ratio in high_cardinality_columns:\n",
    "    print(f\"Kolon: {column}, Cardinality: {count}, Oran: {ratio}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f99bbac-4de4-4cf3-9be6-0404d195798e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T16:02:13.373677Z",
     "iopub.status.busy": "2024-05-30T16:02:13.373417Z",
     "iopub.status.idle": "2024-05-30T16:02:13.376517Z",
     "shell.execute_reply": "2024-05-30T16:02:13.376076Z",
     "shell.execute_reply.started": "2024-05-30T16:02:13.373659Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_column_value_counts(df, column):\n",
    "    \"\"\"Belirli bir sütundaki benzersiz değerlerin dağılımını ve bunların ne sıklıkta göründüğünü belirler.\"\"\"\n",
    "    value_counts = df.groupBy(column).count().orderBy('count', ascending=False)\n",
    "    return value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "814c90bc-5330-416a-9e5c-896d7a09881c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T16:02:19.196411Z",
     "iopub.status.busy": "2024-05-30T16:02:19.195702Z",
     "iopub.status.idle": "2024-05-30T16:02:22.477572Z",
     "shell.execute_reply": "2024-05-30T16:02:22.477217Z",
     "shell.execute_reply.started": "2024-05-30T16:02:19.196364Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|year|   count|\n",
      "+----+--------+\n",
      "|2017|75061598|\n",
      "|2016|37333145|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Örneğin 'p_date' sütunu için değer sayılarını alalım\n",
    "value_counts = get_column_value_counts(weather, 'year')\n",
    "\n",
    "# Sonuçları yazdıralım\n",
    "value_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2f96d15-5338-46fc-9344-bbc83df78379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T16:03:59.601475Z",
     "iopub.status.busy": "2024-05-30T16:03:59.601043Z",
     "iopub.status.idle": "2024-05-30T16:03:59.605792Z",
     "shell.execute_reply": "2024-05-30T16:03:59.605258Z",
     "shell.execute_reply.started": "2024-05-30T16:03:59.601449Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_column_value_counts(df):\n",
    "    \"\"\"Verilen DataFrame'deki tüm sütunlardaki benzersiz değerlerin dağılımını ve bunların geliş sıklığını belirler.\"\"\"\n",
    "    column_list = df.columns\n",
    "    all_column_counts = {}\n",
    "\n",
    "    for column in column_list:\n",
    "        value_counts = df.groupBy(column).count().orderBy('count', ascending=False)\n",
    "        all_column_counts[column] = value_counts\n",
    "    \n",
    "    return all_column_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb926f00-0026-444b-b84c-231ae21f9738",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:24:33.412114Z",
     "iopub.status.busy": "2024-05-31T12:24:33.411609Z",
     "iopub.status.idle": "2024-05-31T12:24:33.426035Z",
     "shell.execute_reply": "2024-05-31T12:24:33.425483Z",
     "shell.execute_reply.started": "2024-05-31T12:24:33.412076Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "\n",
    "def get_top_value_counts(df):\n",
    "    \"\"\"Verilen DataFrame içerisindeki tüm sütunlardaki en yüksek değerli kayıtları DataFrame olarak döndürür.\"\"\"\n",
    "    top_value_counts = []\n",
    "    spark.sparkContext.setJobDescription('df count')  # Setting Job description\n",
    "    total_rows = df.count()\n",
    "\n",
    "    for column in df.columns:\n",
    "        # Null kontrolü\n",
    "        spark.sparkContext.setJobDescription(f'df group by count sort {column}')  # Setting Job description\n",
    "        col_count = df.groupBy(column).count().sort(desc(\"count\"))\n",
    "        \n",
    "        spark.sparkContext.setJobDescription(f'df approx distinct count {column}')  # Setting Job description\n",
    "        approx_distinct_value = df.agg(approx_count_distinct(column)).collect()[0][0]\n",
    "        \n",
    "        spark.sparkContext.setJobDescription(f'df head {column}')  # Setting Job description\n",
    "        if col_count.head() is not None:\n",
    "            spark.sparkContext.setJobDescription(f'df first {column}')  # Setting Job description\n",
    "            row = col_count.first()\n",
    "            ratio = round((row[1] / total_rows) * 100, 2)  # calculate the ratio\n",
    "            top_value_counts.append(Row(column, row[0], row[1], ratio, approx_distinct_value))\n",
    "\n",
    "    result_df = spark.createDataFrame(top_value_counts, [\"Column\", \"Value\", \"Count\", \"Ratio\", \"Approx_Distinct_Value\"])\n",
    "\n",
    "    return result_df.sort(desc(\"Count\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7cb52b5-2a5a-41fd-81bc-9cd112e631d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T11:29:26.294179Z",
     "iopub.status.busy": "2024-05-31T11:29:26.294031Z",
     "iopub.status.idle": "2024-05-31T11:29:26.296842Z",
     "shell.execute_reply": "2024-05-31T11:29:26.296584Z",
     "shell.execute_reply.started": "2024-05-31T11:29:26.294168Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setJobDescription('without agg')  # Setting Job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58236627-fed6-4167-b146-e89de57e0089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:24:53.806214Z",
     "iopub.status.busy": "2024-05-31T12:24:53.805482Z",
     "iopub.status.idle": "2024-05-31T12:40:49.527010Z",
     "shell.execute_reply": "2024-05-31T12:40:49.526097Z",
     "shell.execute_reply.started": "2024-05-31T12:24:53.806160Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/31 15:26:38 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/31 15:28:02 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/31 15:30:18 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/31 15:31:30 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+-----+---------------------+\n",
      "|    Column|     Value|    Count|Ratio|Approx_Distinct_Value|\n",
      "+----------+----------+---------+-----+---------------------+\n",
      "|      year|      2018|450787193|12.51|                    8|\n",
      "|     month|        12|305168464| 8.47|                   12|\n",
      "|       day|        29|118024836| 3.27|                   32|\n",
      "| wthr_date|2017-08-29| 59064864| 1.64|                   92|\n",
      "|avg_tmpr_c|      28.4| 18089988|  0.5|                  884|\n",
      "|avg_tmpr_f|      83.1|  9078272| 0.25|                 1602|\n",
      "|       lat|   66.7461|  4773296| 0.13|               333940|\n",
      "|       lng|   19.2272|  1671240| 0.05|               324657|\n",
      "+----------+----------+---------+-----+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame'i oluşturalım ve yazdıralım\n",
    "spark.conf.set(\"spark.sql.parquet.aggregatePushdown\", True)\n",
    "top_value_df = get_top_value_counts(weather)\n",
    "top_value_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "346314d6-c01a-4430-a5f9-3678e30504b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T11:44:42.738174Z",
     "iopub.status.busy": "2024-05-31T11:44:42.737987Z",
     "iopub.status.idle": "2024-05-31T11:44:42.740374Z",
     "shell.execute_reply": "2024-05-31T11:44:42.740071Z",
     "shell.execute_reply.started": "2024-05-31T11:44:42.738162Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setJobDescription('with agg')  # Setting Job description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e360af08-551a-4c02-8b97-2525f2fc9dc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T11:44:42.741403Z",
     "iopub.status.busy": "2024-05-31T11:44:42.741330Z",
     "iopub.status.idle": "2024-05-31T11:44:42.744364Z",
     "shell.execute_reply": "2024-05-31T11:44:42.744173Z",
     "shell.execute_reply.started": "2024-05-31T11:44:42.741397Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.aggregatePushdown\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc5d27f4-070f-4fbd-9aff-6c66dc4ebc13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T11:44:42.744687Z",
     "iopub.status.busy": "2024-05-31T11:44:42.744627Z",
     "iopub.status.idle": "2024-05-31T12:16:21.442930Z",
     "shell.execute_reply": "2024-05-31T12:16:21.442009Z",
     "shell.execute_reply.started": "2024-05-31T11:44:42.744681Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/31 15:03:11 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "24/05/31 15:07:26 WARN RowBasedKeyValueBatch: Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---------+-----+---------------------+\n",
      "|    Column|     Value|    Count|Ratio|Approx_Distinct_Value|\n",
      "+----------+----------+---------+-----+---------------------+\n",
      "|      year|      2018|450787193|12.51|                    8|\n",
      "|     month|        12|305168464| 8.47|                   12|\n",
      "|       day|        29|118024836| 3.27|                   32|\n",
      "| wthr_date|2017-08-29| 59064864| 1.64|                   92|\n",
      "|avg_tmpr_c|      28.4| 18089988|  0.5|                  884|\n",
      "|avg_tmpr_f|      83.1|  9078272| 0.25|                 1602|\n",
      "|       lat|   66.7461|  4773296| 0.13|               333940|\n",
      "|       lng|   19.2272|  1671240| 0.05|               324657|\n",
      "+----------+----------+---------+-----+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DataFrame'i oluşturalım ve yazdıralım\n",
    "top_value_df = get_top_value_counts(weather)\n",
    "top_value_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b3e8d00-6a84-4b1a-aa50-16e66d9650ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T12:16:21.444967Z",
     "iopub.status.busy": "2024-05-31T12:16:21.444814Z",
     "iopub.status.idle": "2024-05-31T12:16:21.489686Z",
     "shell.execute_reply": "2024-05-31T12:16:21.487902Z",
     "shell.execute_reply.started": "2024-05-31T12:16:21.444928Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.30:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pySparkSetup</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x108c91790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11b5b658-d77e-4f5a-8414-7abc220192c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T00:11:41.027649Z",
     "iopub.status.busy": "2024-05-31T00:11:41.026937Z",
     "iopub.status.idle": "2024-05-31T00:11:41.686939Z",
     "shell.execute_reply": "2024-05-31T00:11:41.686610Z",
     "shell.execute_reply.started": "2024-05-31T00:11:41.027603Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+---------+----------------------+\n",
      "|file_path                                                                                                                                              |file_name                                                          |file_size|file_modification_time|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+---------+----------------------+\n",
      "|file:/Users/ugurkalkavan/Downloads/m06sparkbasics/weather/year=2017/month=08/day=29/part-00088-44bd3411-fbe4-4e16-b667-7ec0fc3ad489.c000.snappy.parquet|part-00088-44bd3411-fbe4-4e16-b667-7ec0fc3ad489.c000.snappy.parquet|6098626  |2023-01-12 04:42:47   |\n",
      "|file:/Users/ugurkalkavan/Downloads/m06sparkbasics/weather/year=2017/month=08/day=29/part-00088-44bd3411-fbe4-4e16-b667-7ec0fc3ad489.c000.snappy.parquet|part-00088-44bd3411-fbe4-4e16-b667-7ec0fc3ad489.c000.snappy.parquet|6098626  |2023-01-12 04:42:47   |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------+---------+----------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select(\"_metadata.file_path\", \"_metadata.file_name\",\"_metadata.file_size\", \"_metadata.file_modification_time\").show(2,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "93e396f5-3510-46b7-9d7f-0fe0eafad425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T00:13:29.211647Z",
     "iopub.status.busy": "2024-05-31T00:13:29.210956Z",
     "iopub.status.idle": "2024-05-31T00:13:29.572926Z",
     "shell.execute_reply": "2024-05-31T00:13:29.572507Z",
     "shell.execute_reply.started": "2024-05-31T00:13:29.211602Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|file_block_length|\n",
      "+-----------------+\n",
      "|6098626          |\n",
      "+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select(\"_metadata.file_block_length\").show(1,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4a8669e-df72-4262-919e-f52edf513bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T00:28:05.404588Z",
     "iopub.status.busy": "2024-05-31T00:28:05.402963Z",
     "iopub.status.idle": "2024-05-31T00:28:05.425778Z",
     "shell.execute_reply": "2024-05-31T00:28:05.425324Z",
     "shell.execute_reply.started": "2024-05-31T00:28:05.404522Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[lng: double, lat: double, avg_tmpr_f: double, avg_tmpr_c: double, wthr_date: string, year: int, month: int, day: int]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0516ef1a-992f-430f-8901-58ebcc21d1ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T00:46:07.367658Z",
     "iopub.status.busy": "2024-05-31T00:46:07.366698Z",
     "iopub.status.idle": "2024-05-31T00:46:11.067439Z",
     "shell.execute_reply": "2024-05-31T00:46:11.066973Z",
     "shell.execute_reply.started": "2024-05-31T00:46:07.367617Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|day|  count|\n",
      "+---+-------+\n",
      "| 28|3665331|\n",
      "| 27|3665331|\n",
      "| 26|3665331|\n",
      "|  9|3665331|\n",
      "|  8|3665331|\n",
      "| 23|3665331|\n",
      "|  7|3665331|\n",
      "| 10|3665331|\n",
      "| 25|3665331|\n",
      "| 24|3665331|\n",
      "| 29|3665331|\n",
      "| 30|3665331|\n",
      "| 12|3665331|\n",
      "| 22|3665331|\n",
      "|  1|3665331|\n",
      "| 13|3665331|\n",
      "|  6|3665331|\n",
      "| 20|3665331|\n",
      "|  5|3665331|\n",
      "| 15|3665331|\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+\n",
      "|count(day)|\n",
      "+----------+\n",
      "| 112394743|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.aggregatePushdown\", False)\n",
    "spark.sparkContext.setJobDescription('without agg day')  # Setting Job description\n",
    "weather.groupBy(\"day\").count().sort(desc(\"count\")).show()\n",
    "weather.agg({\"day\": \"count\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "620e6436-fd01-4004-8d0d-941e724942cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T00:28:31.082271Z",
     "iopub.status.busy": "2024-05-31T00:28:31.082210Z",
     "iopub.status.idle": "2024-05-31T00:28:32.496852Z",
     "shell.execute_reply": "2024-05-31T00:28:32.496320Z",
     "shell.execute_reply.started": "2024-05-31T00:28:31.082265Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:===================================>                     (10 + 6) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|day|  count|\n",
      "+---+-------+\n",
      "| 28|3665331|\n",
      "| 27|3665331|\n",
      "| 26|3665331|\n",
      "|  9|3665331|\n",
      "|  8|3665331|\n",
      "| 23|3665331|\n",
      "|  7|3665331|\n",
      "| 10|3665331|\n",
      "| 25|3665331|\n",
      "| 24|3665331|\n",
      "| 29|3665331|\n",
      "| 30|3665331|\n",
      "| 12|3665331|\n",
      "| 22|3665331|\n",
      "|  1|3665331|\n",
      "| 13|3665331|\n",
      "|  6|3665331|\n",
      "| 20|3665331|\n",
      "|  5|3665331|\n",
      "| 15|3665331|\n",
      "+---+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.aggregatePushdown\", True)\n",
    "spark.sparkContext.setJobDescription('with agg day')  # Setting Job description\n",
    "weather.groupBy(\"day\").count().sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bb10425-2e45-4b76-9efc-f45ded1fba71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T00:28:32.508621Z",
     "iopub.status.busy": "2024-05-31T00:28:32.508552Z",
     "iopub.status.idle": "2024-05-31T00:28:36.654869Z",
     "shell.execute_reply": "2024-05-31T00:28:36.654546Z",
     "shell.execute_reply.started": "2024-05-31T00:28:32.508615Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:==============================================>          (13 + 3) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "| wthr_date|  count|\n",
      "+----------+-------+\n",
      "|2017-08-31|1230518|\n",
      "|2017-08-27|1230518|\n",
      "|2017-08-26|1230518|\n",
      "|2017-09-10|1230518|\n",
      "|2017-08-23|1230518|\n",
      "|2017-08-25|1230518|\n",
      "|2017-09-09|1230518|\n",
      "|2017-09-08|1230518|\n",
      "|2017-08-29|1230518|\n",
      "|2017-08-30|1230518|\n",
      "|2017-08-28|1230518|\n",
      "|2017-09-07|1230518|\n",
      "|2017-08-24|1230518|\n",
      "|2017-09-12|1230518|\n",
      "|2017-08-10|1230518|\n",
      "|2017-09-06|1230518|\n",
      "|2017-09-13|1230518|\n",
      "|2017-08-22|1230518|\n",
      "|2017-09-01|1230518|\n",
      "|2017-08-15|1230518|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.aggregatePushdown\", False)\n",
    "spark.sparkContext.setJobDescription('without agg wthr_date')  # Setting Job description\n",
    "weather.groupBy(\"wthr_date\").count().sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c805847-3ff2-4a61-8fd9-8790e34a48f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T00:28:36.669056Z",
     "iopub.status.busy": "2024-05-31T00:28:36.668988Z",
     "iopub.status.idle": "2024-05-31T00:28:38.798593Z",
     "shell.execute_reply": "2024-05-31T00:28:38.798179Z",
     "shell.execute_reply.started": "2024-05-31T00:28:36.669050Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:====================================================>   (15 + 1) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "| wthr_date|  count|\n",
      "+----------+-------+\n",
      "|2017-08-31|1230518|\n",
      "|2017-08-27|1230518|\n",
      "|2017-08-26|1230518|\n",
      "|2017-09-10|1230518|\n",
      "|2017-08-23|1230518|\n",
      "|2017-08-25|1230518|\n",
      "|2017-09-09|1230518|\n",
      "|2017-09-08|1230518|\n",
      "|2017-08-29|1230518|\n",
      "|2017-08-30|1230518|\n",
      "|2017-08-28|1230518|\n",
      "|2017-09-07|1230518|\n",
      "|2017-08-24|1230518|\n",
      "|2017-09-12|1230518|\n",
      "|2017-08-10|1230518|\n",
      "|2017-09-06|1230518|\n",
      "|2017-09-13|1230518|\n",
      "|2017-08-22|1230518|\n",
      "|2017-09-01|1230518|\n",
      "|2017-08-15|1230518|\n",
      "+----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.aggregatePushdown\", True)\n",
    "spark.sparkContext.setJobDescription('with agg wthr_date')  # Setting Job description\n",
    "weather.groupBy(\"wthr_date\").count().sort(desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "285c2fc6-aa44-4438-bc3c-b930a4bd2e48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-31T00:28:38.812726Z",
     "iopub.status.busy": "2024-05-31T00:28:38.812632Z",
     "iopub.status.idle": "2024-05-31T00:28:38.827771Z",
     "shell.execute_reply": "2024-05-31T00:28:38.827488Z",
     "shell.execute_reply.started": "2024-05-31T00:28:38.812715Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.30:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pySparkSetup</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1060f19d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87371b-45bd-441f-8c20-434ae8abf15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
